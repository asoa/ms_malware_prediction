{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary of Project\n",
    "* This notebook models data from https://www.kaggle.com/c/microsoft-malware-prediction/overview\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO\n",
    "---\n",
    "* [x] analyze correlation of features using chi-squared statistic\n",
    "* [x] reduce cardinality of features using discretization/hasing trick techniques\n",
    "* [ ] grid search LR model regParam and elasticNet parameters \n",
    "* [ ] create random forest and gradient-boosted tree models\n",
    "* [x] enable Adaptive Query Execution to handle data skew, shuffle, and join logic\n",
    "* [ ] fix driver.maxResultSize error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Environment setup\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.conf import SparkConf\n",
    "from pyspark.storagelevel import StorageLevel\n",
    "from pyspark.sql import SparkSession, DataFrame\n",
    "from pyspark.ml import feature, evaluation, Pipeline\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "import pyspark.sql.functions as F\n",
    "import pyspark.sql.types as T\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import re\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyspark.conf.SparkConf at 0x7f0cf592e110>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conf = (SparkConf()\n",
    "            .setAppName('ms_malware_pred')\n",
    "            .setMaster('spark://spark-master:7077')\n",
    "       )\n",
    "conf.set(\"spark.executor.cores\", \"2\")\n",
    "conf.set(\"spark.executor.memory\", \"16g\")\n",
    "conf.set(\"spark.driver.maxResultSize\", \"1g\")\n",
    "conf.set(\"spark.default.parallelism\", \"6\")  # default number of cores in application\n",
    "conf.set(\"spark.driver.memory\", \"3g\") # may need to increase (from 3) due to list of fe dfs\n",
    "conf.set(\"spark.shuffle.file.buffer\", \"1m\")\n",
    "conf.set(\"spark.shuffle.unsafe.file.output.buffer\", \"1m\")\n",
    "conf.set(\"spark.sql.shuffle.partitions\", \"18\")  # 3 * cores available (6)\n",
    "conf.set(\"spark.sql.adaptive.enabled\", \"true\") # enable Adaptive Query Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.config(conf=conf).getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('spark.sql.shuffle.partitions', '18'),\n",
       " ('spark.default.parallelism', '6'),\n",
       " ('spark.driver.port', '33043'),\n",
       " ('spark.sql.adaptive.enabled', 'true'),\n",
       " ('spark.executor.id', 'driver'),\n",
       " ('spark.app.id', 'app-20200905171859-0006'),\n",
       " ('spark.driver.maxResultSize', '1g'),\n",
       " ('spark.app.name', 'ms_malware_pred'),\n",
       " ('spark.executor.cores', '2'),\n",
       " ('spark.shuffle.unsafe.file.output.buffer', '1m'),\n",
       " ('spark.executor.memory', '16g'),\n",
       " ('spark.driver.host', 'e2e0670c0779'),\n",
       " ('spark.driver.memory', '3g'),\n",
       " ('spark.shuffle.file.buffer', '1m'),\n",
       " ('spark.rdd.compress', 'True'),\n",
       " ('spark.master', 'spark://spark-master:7077'),\n",
       " ('spark.serializer.objectStreamReset', '100'),\n",
       " ('spark.submit.pyFiles', ''),\n",
       " ('spark.submit.deployMode', 'client'),\n",
       " ('spark.ui.showConsoleProgress', 'true')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sparkContext.getConf().getAll()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def file_io(operation='clean'):\n",
    "    if operation == 'orig':\n",
    "        print('reading in original train.csv')\n",
    "        df = (spark.read.format('csv')\n",
    "          .option('inferSchema', 'true')\n",
    "          .option('header', 'true')\n",
    "          .option('quote', '\\\"')\n",
    "          .option('escape', '\\\"')\n",
    "          .load('hdfs://namenode:9000/data/train.csv') # train|test.csv\n",
    "         )\n",
    "        \n",
    "        (df\n",
    "         .coalesce(1) \n",
    "         .write.format('parquet')\n",
    "         .mode('overwrite')\n",
    "         .save('hdfs://namenode:9000/data/train.parquet')\n",
    "        )\n",
    "        \n",
    "    elif operation == 'clean':\n",
    "        print('reading in train.parquet')\n",
    "        df = spark.read.parquet('hdfs://namenode:9000/data/train.parquet')\n",
    "        df.persist(StorageLevel.MEMORY_AND_DISK)\n",
    "        df.count()\n",
    "        return df\n",
    "    \n",
    "    elif operation == 'train':\n",
    "        print('reading in df_fe.parquet')\n",
    "        df_train = spark.read.parquet('hdfs://namenode:9000/data/df_fe.parquet')\n",
    "        df_train.persist(StorageLevel.MEMORY_AND_DISK)\n",
    "        df_train.count()\n",
    "        return df_train\n",
    "    \n",
    "    else:\n",
    "        print('reading in df_test.parquet')\n",
    "        df_test = spark.read.parquet('hdfs://namenode:9000/data/df_test.parquet')\n",
    "        df_test.persist(StorageLevel.MEMORY_AND_DISK)\n",
    "        df_test.count()\n",
    "        return df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file_io(operation='orig')\n",
    "# df = file_io(operation='clean')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper functions\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# added 'MachineIdentifier' in numeric list to enable common join \n",
    "numeric_cols = []\n",
    "def get_num_cols(_df):\n",
    "    global numeric_cols\n",
    "    numeric_cols = [x[0] for x in _df.dtypes if x[1] in ['int', 'double']]\n",
    "    return numeric_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "string_cols = []\n",
    "def get_string_cols(_df):\n",
    "    global string_cols\n",
    "    string_cols = [x[0] for x in _df.dtypes if x[1] == 'string']\n",
    "    return string_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_null_count(_df, _col):\n",
    "    # return count of null values in _col\n",
    "    df1 = _df.select(F.count(F.when(F.isnull(_col), _col)).alias('null_count'))\n",
    "    df2 = _df.groupby(_col).count().sort(F.desc('count'))\n",
    "    df1.show()\n",
    "    df2.show(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pivot_plot(_df, col, count=20):\n",
    "    col_distinct_count = _df.select(col).distinct().count()\n",
    "    pdf = (_df.groupby(col, 'HasDetections')\n",
    "           .agg(F.count(col).alias(col+'Count'), F.count('HasDetections').alias('HasDetectionsCount'))\n",
    "           .sort(F.desc(col+'Count'))\n",
    "           .limit(count)\n",
    "           .selectExpr(\n",
    "               col,'HasDetections','HasDetectionsCount'\n",
    "           )).toPandas()\n",
    "    print(f\"Distinct values count: {col_distinct_count}\")\n",
    "    return pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_type(col):\n",
    "    d = dict(df.dtypes)\n",
    "    return d.get(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Plot:\n",
    "    \"\"\" \n",
    "    takes a col keyword for the column to plot, gets a pandas data frame and plots a sns catplot\n",
    "    of the top 40 col factors and their 'HasDetections' count\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, *args, **kwargs):\n",
    "        self.kwargs = {k:v for k,v in kwargs.items()}\n",
    "        self.col = kwargs.get('col')\n",
    "        self._df = kwargs.get('df')\n",
    "        self._plot(self._get_seaborn_pdf())\n",
    "        \n",
    "    def _get_seaborn_pdf(self):\n",
    "        pdf = (self._df.groupby(self.col, 'HasDetections')\n",
    "               .agg(F.count(self.col).alias(self.col+'Count'), F.count('HasDetections').alias('HasDetectionsCount'))\n",
    "               .sort(F.desc(self.col+'Count'))\n",
    "               .limit(40)\n",
    "               .selectExpr(\n",
    "                   self.col,self.col+'Count','HasDetections','HasDetectionsCount'\n",
    "               )).toPandas()\n",
    "        return pdf\n",
    "    \n",
    "    def _plot(self, pdf):\n",
    "        g = sns.catplot(x=self.col, y='HasDetectionsCount', data=pdf, kind='bar', hue='HasDetections')\n",
    "        g.set_xticklabels(rotation=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def truncate(col):\n",
    "    print(f\"Original count of unique values: {df.select(col).distinct().count()}\")\n",
    "    fe_col_name = col + '_fe'\n",
    "    _df = (df_fe.withColumn(fe_col_name, F.regexp_extract(col,r'\\d.\\d+.(\\d+).\\d+',1))  # change regex capture group to truncate field\n",
    "        .groupby(fe_col_name, 'HasDetections').count().sort(F.desc('count'))\n",
    "    )\n",
    "    Plot(col=col)\n",
    "    print(f\"Count of unique values: {_df.select(fe_col_name).distinct().count()}\")\n",
    "    pdf = _df.toPandas().loc[:40,]\n",
    "#     print(pdf.loc[:,fe_col_name].values)\n",
    "    f, ax = plt.subplots(figsize=(11, 9))\n",
    "#     g = (sns.catplot(x=fe_col_name, y='count', data=pdf, kind='bar', order=pdf.loc[:,fe_col_name].values)\n",
    "#          .set_xticklabels(labels=pdf.loc[:,fe_col_name].values,rotation=90)\n",
    "#         )\n",
    "    g = (sns.barplot(x=fe_col_name, y='count', hue='HasDetections', data=pdf, order=pdf.loc[:,fe_col_name].values)\n",
    "     .set_xticklabels(labels=pdf.loc[:,fe_col_name].values, rotation=90)\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning/EDA\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop columns with high occurence of null values > 70%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_df = df.select(\n",
    "    # get count of null values for each column\n",
    "    [(F.count(F.when(F.isnull(c), c))).alias(c) for c in df.columns]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create pandas dataframe: values are null counts of each column\n",
    "pdf = pd.DataFrame([_df.select(col).first() for col in _df.columns], _df.columns, columns=['count_null_values'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf = pdf.sort_values('count_null_values', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_rows = df.count()\n",
    "pdf['null_ratio'] = pdf.count_null_values/num_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop_cols = ['PuaMode','Census_ProcessorClass','DefaultBrowsersIdentifier','Census_IsFlightingInternal','Census_InternalBatteryType']\n",
    "drop_cols = list(pdf[(pdf['null_ratio'] > .70)].index.values)\n",
    "drop_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(*drop_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Impute remaining missing values to -1 for numeric and '-1' for string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_num_cols(df)\n",
    "get_string_cols(df)\n",
    "df = df.fillna(-1, numeric_cols)\n",
    "df = df.fillna('-1', string_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split cols into numeric and string groups\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_num_cols(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_string_cols(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get skewness of columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df_skew = df.select(\n",
    "   [F.skewness(_col).alias(_col) for _col in df.columns]\n",
    ")\n",
    "pdf_skew = pd.DataFrame([df_skew.select(_col).first() for _col in df_skew.columns], df_skew.columns, columns=['skewness'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_skew.sort_values('skewness', ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize skewed features before dropping\n",
    "* can't use for test.csv because `HasDetections` column is not present"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot_plot(df, 'Census_PrimaryDiskTotalCapacity')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = Plot(df=df, col='Census_PrimaryDiskTotalCapacity')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Maybe this could be a discriminating feature? But it's cardinality is very high--perhaps use hashing trick/binning to reduce dimensionality\n",
    "* Hashing/binning reduces model interpretability, perhaps use quartile transformation to maintain some sense of original unit?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = Plot(df=df, col='UacLuaenable')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = Plot(df=df,col='SmartScreen')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* After reviewing the plot of this feature *SmartScreen*, decided not to drop it due to the potential discriminating effect at predicting P(Y|x)\n",
    "* TODO: write function to standardize values (e.g. off -> Off)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot_plot(df, 'SmartScreen')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Plot(df=df,col='IsBeta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Plot(df=df,col='AutoSampleOptIn')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop skewed columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# skew_drop_cols = ['IsBeta', 'AutoSampleOptIn', 'UacLuaenable']\n",
    "skew_drop_cols = pdf_skew[pdf_skew['skewness'] > 100]\n",
    "skew_drop_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skew_drop_cols = [col for col in list(skew_drop_cols.index.values) if col not in ['SmartScreen', 'Census_PrimaryDiskTotalCapacity']]\n",
    "skew_drop_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(*skew_drop_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_num_cols(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_string_cols(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze distribution of columns by HasDetections column\n",
    "* can't use for test.csv because `HasDetections` column is not present"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Plot(df=df,col='CountryIdentifier')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Plot(df=df,col='Census_OSVersion')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Plot(df=df,col='RtpStateBitfield')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* not sure why this feature didn't show as skewed in earlier analysis -- clearly it is skewed and doesn't appear to provide much predication power"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot_plot(df,'RtpStateBitfield')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = Plot(df=df,col='EngineVersion')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = Plot(df=df,col='AppVersion')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = Plot(df=df,col='AvSigVersion')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get relative frequency of largest factor for each categorical feature\n",
    "* drop columns where one factor is greater than 90% of column density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "def analyze_rel_freq():\n",
    "    cols = df.columns\n",
    "    rel_freqs = []\n",
    "    for col in cols:\n",
    "        rel_freqs.append((col, (df.groupby(col)\n",
    "         .count()\n",
    "         .withColumn('rel_freq', F.col('count')/df.count())\n",
    "         .orderBy(F.desc('count')).orderBy(F.desc('rel_freq'))\n",
    "        ).rdd.take(1)[0].rel_freq))\n",
    "    return rel_freqs\n",
    "rel_freqs = analyze_rel_freq()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rel_freqs = [('MachineIdentifier', 1.1208898789584646e-07), ('ProductName', 0.9893556934424468), ('EngineVersion', 0.43098966842171865), ('AppVersion', 0.5760504167300436), ('AvSigVersion', 0.011468608974539322), ('RtpStateBitfield', 0.969736421624073), ('IsSxsPassiveMode', 0.9826662226448226), ('AVProductStatesIdentifier', 0.652869595783571), ('AVProductsInstalled', 0.6959485323236059), ('AVProductsEnabled', 0.9700294222384328), ('HasTpm', 0.9879710581749693), ('CountryIdentifier', 0.04451860750056913), ('CityIdentifier', 0.0364747654621995), ('OrganizationIdentifier', 0.47037661787844015), ('GeoNameIdentifier', 0.17171237113829618), ('LocaleEnglishNameIdentifier', 0.23477991271182155), ('Platform', 0.9660630413127503), ('Processor', 0.9085300056055703), ('OsVer', 0.9676132320153499), ('OsBuild', 0.43888678597493264), ('OsSuite', 0.6232888635219055), ('OsPlatformSubRelease', 0.43888734641987215), ('OsBuildLab', 0.4100438234315976), ('SkuEdition', 0.6180969016025699), ('IsProtected', 0.9418032853954886), ('SMode', 0.9392881205960937), ('IeVerIdentifier', 0.4355600969031718), ('SmartScreen', 0.48379658404325826), ('Firewall', 0.9685625136538398), ('Census_MDC2FormFactor', 0.6415210341150681), ('Census_DeviceFamily', 0.998382555904663), ('Census_OEMNameIdentifier', 0.14428935189362577), ('Census_OEMModelIdentifier', 0.034162705908871875), ('Census_ProcessorCoreCount', 0.6086648374491102), ('Census_ProcessorManufacturerIdentifier', 0.8787012204136914), ('Census_ProcessorModelIdentifier', 0.03242543868547415), ('Census_PrimaryDiskTotalCapacity', 0.3185042217756846), ('Census_PrimaryDiskTypeName', 0.6508787832695528), ('Census_SystemVolumeTotalCapacity', 0.005940940536455655), ('Census_HasOpticalDiskDrive', 0.9228127207102227), ('Census_TotalPhysicalRAM', 0.4589497060073981), ('Census_ChassisTypeName', 0.5883340247355737), ('Census_InternalPrimaryDiagonalDisplaySizeInInches', 0.34158345647242727), ('Census_InternalPrimaryDisplayResolutionHorizontal', 0.5060889540449721), ('Census_InternalPrimaryDisplayResolutionVertical', 0.5574881440675278), ('Census_PowerPlatformRoleName', 0.6930358999731323), ('Census_InternalBatteryNumberOfCharges', 0.5664309397888221), ('Census_OSVersion', 0.15845201969224174), ('Census_OSArchitecture', 0.9085804456501234), ('Census_OSBranch', 0.449382462534536), ('Census_OSBuildNumber', 0.44935141388488886), ('Census_OSBuildRevision', 0.15845269222616912), ('Census_OSEdition', 0.3889477791976962), ('Census_OSSkuName', 0.38893410434117287), ('Census_OSInstallTypeName', 0.29233222772491974), ('Census_OSInstallLanguageIdentifier', 0.3563602598357246), ('Census_OSUILocaleIdentifier', 0.3554144529558595), ('Census_OSWUAutoUpdateOptionsName', 0.4432555663671612), ('Census_IsPortableOperatingSystem', 0.9994547991628746), ('Census_GenuineStateName', 0.8829918747813564), ('Census_ActivationChannel', 0.5299106661975369), ('Census_IsFlightsDisabled', 0.9819972755650602), ('Census_FlightRing', 0.9365796022925785), ('Census_ThresholdOptIn', 0.635244723326828), ('Census_FirmwareManufacturerIdentifier', 0.3025369212719455), ('Census_FirmwareVersionIdentifier', 0.017949145898725583), ('Census_IsSecureBootEnabled', 0.5139771044791545), ('Census_IsWIMBootEnabled', 0.6343903810610859), ('Census_IsVirtualDevice', 0.991184985724907), ('Census_IsTouchEnabled', 0.8744568587980271), ('Census_IsPenCapable', 0.9619290873501637), ('Census_IsAlwaysOnAlwaysConnectedCapable', 0.9350431985354901), ('Wdft_IsGamer', 0.6920534399942252), ('Wdft_RegionIdentifier', 0.2017719475562527), ('HasDetections', 0.5002073085831134)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_rel_freq_gt_90 = [x[0] for x in sorted(rel_freqs, key=lambda x: x[1], reverse=True) if x[1] > .9]\n",
    "drop_rel_freq_gt_90"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(*drop_rel_freq_gt_90)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering\n",
    "* [x] TODO: Discretize Census_SystemVolumeTotalCapacity [299451]\n",
    "* [-] TODO: Discretize Census_OEMModelIdentifier\n",
    "* [x] TODO: Standardize *SmartScreen* values\n",
    "* [x] TODO: Discretize (hashing trick/binning) of *Census_PrimaryDiskTotalCapacity*; decided to discretize based on quartile values\n",
    "* [x] TODO: Truncate EngineVersion [1.1.15100.1]\n",
    "* [x] TODO: Truncate AppVersion [4.18.1807.18075]\n",
    "* [x] TODO: Truncate AvSigVersion [1.273.1735.0]\n",
    "* [x] TODO: Discretize Census_InternalBatteryNumberOfCharges [4294967295.0]\n",
    "* [x] TODO: Discretize Census_TotalPhysicalRAM [4096]\n",
    "* [-] TODO: Discretize Census_InternalPrimaryDisplayResolutionHorizontal [1440]\n",
    "* [-] TODO: Discretize Census_InternalPrimaryDisplayResolutionVertical [900]\n",
    "* [x] TODO: Onehot encode categorical data\n",
    "* [x] TODO: Create hashing transformer function\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Cardinality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from pyspark.sql.functions import approx_count_distinct\n",
    "# col_distinct_counts = [(_col, df_fe.select(_col).distinct().count()) for _col in numeric_cols + string_cols]\n",
    "col_distinct_counts = sorted([(_col, df.select(approx_count_distinct(_col, .1)).rdd.take(1)[0][0]) for _col in df.columns], key=lambda x: x[1], reverse=True)\n",
    "col_distinct_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fe = df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discretize `Census_SystemVolumeTotalCapacity`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fe.select('Census_SystemVolumeTotalCapacity').summary().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@F.udf(returnType=T.StringType())\n",
    "def discretize_Census_SystemVolumeTotalCapacity(num):\n",
    "    # (475965.0, INF]\n",
    "    if num > 475798.0:\n",
    "        return 'large'\n",
    "    # (239500.0, 475965.0]\n",
    "    elif (num > 239500.0 and num <= 475965.0): \n",
    "        return 'med'\n",
    "    # (113922.0, 239500.0]\n",
    "    elif (num > 113922.0 and num <= 239500.0):\n",
    "        return 'small'\n",
    "    else:\n",
    "        return 'unknown'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fe = (df_fe.select('*')\n",
    "           .withColumn('Census_SystemVolumeTotalCapacity', discretize_Census_SystemVolumeTotalCapacity(df.Census_SystemVolumeTotalCapacity))\n",
    "     )\n",
    "df_fe.groupby('Census_SystemVolumeTotalCapacity').count().sort(F.desc('count')).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discretize `Census_OEMModelIdentifier`\n",
    "* don't currently see a way to discretize this feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot_plot(df_fe, 'Census_OEMModelIdentifier')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Plot(df=df,col='Census_OEMModelIdentifier')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standardize `SmartScreen` values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fe = (df_fe.select('*')\n",
    "      .withColumn('SmartScreen', F.regexp_replace('SmartScreen', r'off', 'Off'))\n",
    "      .withColumn('SmartScreen', F.regexp_replace('SmartScreen', r'OFF', 'Off'))\n",
    "      .withColumn('SmartScreen', F.regexp_replace('SmartScreen', r'on', 'On'))\n",
    "      .withColumn('SmartScreen', F.regexp_replace('SmartScreen', r'&#x02;', '2'))\n",
    "      .withColumn('SmartScreen', F.regexp_replace('SmartScreen', r'&#x01;', '1'))\n",
    "      .withColumn('SmartScreen', F.regexp_replace('SmartScreen', r'&#x03;', '3'))\n",
    "      .withColumn('SmartScreen', F.regexp_replace('SmartScreen', r'requireadmin', 'RequireAdmin'))\n",
    "      .withColumn('SmartScreen', F.regexp_replace('SmartScreen', r'Promt', 'Prompt'))\n",
    "     )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discretize `Census_PrimaryDiskTotalCapacity`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot_plot(df_fe,'Census_PrimaryDiskTotalCapacity')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fe.select('Census_PrimaryDiskTotalCapacity').summary().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@F.udf(returnType=T.StringType())\n",
    "def discretize_col(num):\n",
    "    # (953869.0, INF]\n",
    "    if num > 953869.0:\n",
    "        return 'large'\n",
    "    # (476940.0, 953869.0]\n",
    "    elif (num > 476940.0 and num <= 953869.0): \n",
    "        return 'med'\n",
    "    # (238475.0, 476940.0]\n",
    "    elif (num > 238475.0 and num <= 476940.0):\n",
    "        return 'small'\n",
    "    else:\n",
    "        return 'unknown'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fe = (df_fe.select('*')\n",
    "           .withColumn('Census_PrimaryDiskTotalCapacity', discretize_col(df.Census_PrimaryDiskTotalCapacity))\n",
    "     )\n",
    "df_fe.groupby('Census_PrimaryDiskTotalCapacity').count().sort(F.desc('count')).show()\n",
    "\n",
    "# verify count \n",
    "# print('small', df.filter((df.Census_PrimaryDiskTotalCapacity > 238475.0) & (df.Census_PrimaryDiskTotalCapacity <= 476940.0)).count())\n",
    "# print('med', df.filter((df.Census_PrimaryDiskTotalCapacity > 476940.0) & (df.Census_PrimaryDiskTotalCapacity <= 953869.0)).count())\n",
    "# print('x-large', df.filter((df.Census_PrimaryDiskTotalCapacity > 953869.0)).count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Plot(df=df_fe,col='Census_SystemVolumeTotalCapacity')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_num_cols(df)\n",
    "get_string_cols(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discretize `EngineVersion` `AppVersion` `AvSigVersion`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fe = df_fe.select('*').withColumn('EngineVersion', F.regexp_extract('EngineVersion',r'\\d.\\d+.(\\d+.\\d+)',1))\n",
    "df_fe = df_fe.select('*').withColumn('AppVersion', F.regexp_extract('AppVersion',r'\\d.\\d+.(\\d+.\\d+)',1))\n",
    "df_fe = df_fe.select('*').withColumn('AvSigVersion', F.regexp_extract('AvSigVersion',r'\\d.\\d+.(\\d+).\\d+',1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discretize `Census_InternalBatteryNumberOfCharges`\n",
    "* dropped feature because of lack of variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fe = (df_fe.select('*')\n",
    "         .withColumn('Census_InternalBatteryNumberOfCharges', (F.col('Census_InternalBatteryNumberOfCharges').cast('int')))\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fe.select('Census_InternalBatteryNumberOfCharges').summary().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot_plot(df_fe, 'Census_InternalBatteryNumberOfCharges')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Plot(df=df_fe,col='Census_InternalBatteryNumberOfCharges')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fe = df_fe.drop('Census_InternalBatteryNumberOfCharges')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discretize `Census_TotalPhysicalRAM`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Plot(df=df_fe,col='Census_TotalPhysicalRAM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot_plot(df_fe, 'Census_TotalPhysicalRAM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fe.select('Census_TotalPhysicalRAM').summary().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize ram by 1024 to reduce cardinality\n",
    "df_fe = (df_fe.select('*')\n",
    "         .withColumn('Census_TotalPhysicalRAM', F.col('Census_TotalPhysicalRAM')/1024)\n",
    "         .withColumn('Census_TotalPhysicalRAM', F.round(F.col('Census_TotalPhysicalRAM'),1))\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Plot(df=df_fe, col='Census_TotalPhysicalRAM')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discretize `Census_InternalPrimaryDisplayResolutionHorizontal|Vertical`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Plot(df=df_fe, col='Census_InternalPrimaryDisplayResolutionHorizontal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Plot(df=df_fe, col='Census_InternalPrimaryDisplayResolutionVertical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_df = (df_fe\n",
    " .withColumn('screen_dims', F.concat(df_fe.Census_InternalPrimaryDisplayResolutionHorizontal, F.lit('*'), df_fe.Census_InternalPrimaryDisplayResolutionVertical))\n",
    " .groupby('screen_dims')\n",
    " .count()\n",
    " .orderBy(F.desc('count'))\n",
    " .show()\n",
    "#  .select('screen_dims').show()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_fe = df_fe.withColumn('screen_dims', F.concat(df_fe.Census_InternalPrimaryDisplayResolutionHorizontal, F.lit('*'), df_fe.Census_InternalPrimaryDisplayResolutionVertical))\n",
    "# df_fe = df_fe.drop('Census_InternalPrimaryDisplayResolutionHorizontal', 'Census_InternalPrimaryDisplayResolutionVertical')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use Hashing Trick to deal with columns with high cardinality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "fe_distinct_count = sorted([(_col, df_fe.select(F.approx_count_distinct(_col, .1)).rdd.take(1)[0][0]) for _col in df_fe.columns], key=lambda x: x[1], reverse=True)\n",
    "fe_distinct_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chi test statistic algorithm seems to not handle features with cardinality > 10000\n",
    "cols = [x[0] for x in fe_distinct_count if x[1] < 10000 and x[0] not in ['MachineIdentifier','HasDetections']] \n",
    "# cols = [x[0] for x in fe_distinct_count if x[0] not in ['MachineIdentifier','HasDetections']] \n",
    "cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fe.persist(StorageLevel.MEMORY_AND_DISK)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fe.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write cleaned/FE DF to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(df_fe\n",
    " .coalesce(1) \n",
    " .write.format('parquet')\n",
    " .mode('overwrite')\n",
    " .save('hdfs://namenode:9000/data/df_fe.parquet')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import FeatureHasher\n",
    "\n",
    "def feature_hasher(df):\n",
    "    hasher = FeatureHasher(numFeatures=32,inputCols=cols,outputCol='hash_features', categoricalCols=cols)\n",
    "    hashed_df = Pipelineine(stages=[\n",
    "        hasher\n",
    "    ]).fit(df).transform(df).select('features','HasDetections')\n",
    "    returned hashed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hashed_df = feature_hasher(df_fe)\n",
    "hashed_df.persist(StorageLevel.MEMORY_AND_DISK)\n",
    "hashed_df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform ChiSquareTest to determine feature independence\n",
    "- (SPSS article) However, this does not mean the variables are strongly associated; a weak association in a large sample size may also result in p = 0.000\n",
    "- (machinelearningmastery.com) The variables are considered independent if the observed and expected frequencies are similar, that the levels of the variables do not interact, are not dependent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chi_test_df = spark.read.parquet('hdfs://namenode:9000/data/df_fe.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexer = feature.StringIndexer(inputCols=cols, outputCols=[col + \"_index\" for col in cols])\n",
    "va = feature.VectorAssembler(inputCols=indexer.getOutputCols(), outputCol='features')\n",
    "\n",
    "def chi_test_pipeline(df):\n",
    "    transformed_df = Pipeline(stages=[\n",
    "        indexer,\n",
    "        va\n",
    "    ]).fit(df).transform(df).select('features','HasDetections')\n",
    "    return transformed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chi_test_df = chi_test_pipeline(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chi_test_df.persist(StorageLevel.MEMORY_AND_DISK)\n",
    "chi_test_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.ml.stat import ChiSquareTest\n",
    "\n",
    "\n",
    "r = ChiSquareTest.test(chi_test_df, \"features\", \"HasDetections\").head()\n",
    "print(\"pValues: \" + str(r.pValues))\n",
    "print(\"degreesOfFreedom: \" + str(r.degreesOfFreedom))\n",
    "print(\"statistics: \" + str(r.statistics))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "chi_pdf = pd.DataFrame(r.statistics.toArray(), index=cols, columns=['chi_stat']).sort_values('chi_stat',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize=(11, 9))\n",
    "g = (sns.barplot(x='chi_stat', y=cols,data=chi_pdf)\n",
    "#      .set_xticklabels(labels='chi_stat', rotation=90)\n",
    "     \n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation Analaysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.stat import Correlation\n",
    "\n",
    "r1 = Correlation.corr(chi_test_df, \"features\").collect()[0][0]\n",
    "# print(\"Pearson correlation matrix:\\n\" + str(r1[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrmatrix = r1.toArray().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_df = spark.createDataFrame(corrmatrix, cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_corr_pdf = corr_df.toPandas()\n",
    "pdf_corr_pdf.index = corr_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a mask for the upper triangle\n",
    "mask = np.triu(np.ones_like(pdf_corr_pdf, dtype=np.bool))\n",
    "\n",
    "f, ax = plt.subplots(figsize=(20,18))\n",
    "\n",
    "# Generate a custom diverging colormap\n",
    "cmap = sns.diverging_palette(220, 10, as_cmap=True)\n",
    "\n",
    "# Draw the heatmap with the mask and correct aspect ratio\n",
    "sns.heatmap(pdf_corr_pdf, mask=mask, cmap=cmap, vmax=.3, center=0,\n",
    "            square=True, linewidths=.5, cbar_kws={\"shrink\": .5})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read-in Cleaned data\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading in df_fe.parquet\n"
     ]
    }
   ],
   "source": [
    "df_train = file_io(operation='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading in df_test.parquet\n"
     ]
    }
   ],
   "source": [
    "df_test = file_io(operation='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Census_ThresholdOptIn', 'Census_IsWIMBootEnabled', 'Census_TotalPhysicalRAM']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_drop_cols = [x for x in (set(df_train.columns) - set(df_test.columns)) if x != 'HasDetections']\n",
    "model_drop_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.drop(*model_drop_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'HasDetections'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(df_train.columns) - set(df_test.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [x for x in df_train.columns if x not in ['MachineIdentifier','HasDetections']] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modeling_pipeline(df, test=False):\n",
    "    cols = [col for col in df.columns if col not in ['MachineIdentifier','HasDetections']]    \n",
    "    indexer = feature.StringIndexer(inputCols=cols, outputCols=[col + \"_index\" for col in cols])\n",
    "    one_hot = feature.OneHotEncoder(inputCols=indexer.getOutputCols(), outputCols=[col + \"_oh\" for col in cols])\n",
    "    va = feature.VectorAssembler(inputCols=indexer.getOutputCols(), outputCol='features')\n",
    "    \n",
    "    fitted_df = Pipeline(stages=[\n",
    "        indexer,\n",
    "        one_hot,\n",
    "        va\n",
    "    ]).fit(df)\n",
    "    \n",
    "    if test:\n",
    "        transformed_df = fitted_df.transform(df).select('MachineIdentifier','features')\n",
    "    else:\n",
    "        transformed_df = fitted_df.transform(df).select('MachineIdentifier','features','HasDetections')\n",
    "    return transformed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "modeling_df = modeling_pipeline(df_train)\n",
    "# testing_df = modeling_pipeline(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_df, validation_df, testing_df = modeling_df.randomSplit([0.6, 0.3, 0.1], seed=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[MachineIdentifier: string, features: vector, HasDetections: int]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_df.persist(StorageLevel.MEMORY_AND_DISK)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2676393"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_df.persist(StorageLevel.MEMORY_ONLY)\n",
    "validation_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5352743"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_df.count()\n",
    "# va_test.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logestic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 37.3 ms, sys: 6.92 ms, total: 44.2 ms\n",
      "Wall time: 4min 32s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "lr = LogisticRegression(featuresCol='features', labelCol='HasDetections')\n",
    "pipeline = Pipeline(stages=[\n",
    "    lr\n",
    "]).fit(training_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n",
      "|      avg(correct)|\n",
      "+------------------+\n",
      "|0.6033463695354158|\n",
      "+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pipeline.transform(validation_df).\\\n",
    "    select(F.expr('float(prediction = HasDetections)').alias('correct')).\\\n",
    "    select(F.avg('correct')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n",
      "|      avg(correct)|\n",
      "+------------------+\n",
      "|0.6025649214935446|\n",
      "+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pipeline.transform(testing_df).\\\n",
    "    select(F.expr('float(prediction = HasDetections)').alias('correct')).\\\n",
    "    select(F.avg('correct')).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LR Model Tuning\n",
    "\n",
    "* [ ] need to reduce cardinality of features before grid-searching\n",
    "* Perform grid-search over regularization parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "paramGrid = (ParamGridBuilder() \n",
    "                 .addGrid(pipeline.stages[0].regParam, [0.0, 0.01, 0.02]) \n",
    "                 .addGrid(pipeline.stages[0].elasticNetParam, [0.0, 0.2, 0.4]) \n",
    "                 .build()\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Loop over each parameter mapping in paramGrid and fit model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting model 0\n",
      "Fitting model 1\n"
     ]
    }
   ],
   "source": [
    "lr_models = []\n",
    "for g in range(len(paramGrid)):\n",
    "    print(\"Fitting model {}\".format(g))\n",
    "    grid_search_pipeline = Pipeline(stages=[\n",
    "        lr\n",
    "    ])\n",
    "    _model = grid_search_pipeline.fit(validation_df, paramGrid[g])\n",
    "    lr_models.append(_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest\n",
    "* [ ] OOM errors; believe these are occuring because of high cardinality of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "rf = RandomForestClassifier(featuresCol='features', labelCol='HasDetections', maxDepth=3, numTrees=10, \n",
    "                            featureSubsetStrategy='sqrt', impurity='gini', seed=0, maxBins=32)\n",
    "pipeline = Pipeline(stages=[\n",
    "#     feature.StringIndexer(inputCol='features',outputCol='str_idx', handleInvalid=\"keep\"),\n",
    "#     feature.OneHotEncoderEstimator(inputCols=['str_idx'], outputCols=['feature']),\n",
    "    rf\n",
    "    \n",
    "]).fit(training_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.transform(validation_df).\\\n",
    "    select(F.avg(F.expr('float(HasDetections = prediction)')).alias('accuracy')).\\\n",
    "    first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.groupby('HasDetections').count().show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
