{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary of Project\n",
    "* This notebook models data from https://www.kaggle.com/c/microsoft-malware-prediction/overview\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO\n",
    "---\n",
    "* [ ] analyze correlation of features using chi-squared statistic\n",
    "* [ ] reduce cardinality of features using discretization/hasing trick techniques\n",
    "* [ ] grid search LR model regParam and elasticNet parameters \n",
    "* [ ] create random forest and gradient-boosted tree models\n",
    "* [x] enable Adaptive Query Execution to handle data skew, shuffle, and join logic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Environment setup\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.conf import SparkConf\n",
    "from pyspark.storagelevel import StorageLevel\n",
    "from pyspark.sql import SparkSession, DataFrame\n",
    "from pyspark.ml import feature, evaluation, Pipeline\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "import pyspark.sql.functions as F\n",
    "import pyspark.sql.types as T\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import re\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyspark.conf.SparkConf at 0x7f87cec01390>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conf = (SparkConf()\n",
    "            .setAppName('ms_malware_pred')\n",
    "            .setMaster('spark://spark-master:7077')\n",
    "       )\n",
    "conf.set(\"spark.executor.cores\", \"2\")\n",
    "conf.set(\"spark.executor.memory\", \"16g\")\n",
    "conf.set(\"spark.driver.maxResultSize\", \"0\")\n",
    "conf.set(\"spark.default.parallelism\", \"6\")  # default number of cores in application\n",
    "conf.set(\"spark.driver.memory\", \"3g\") # may need to increase (from 3) due to list of fe dfs\n",
    "conf.set(\"spark.shuffle.file.buffer\", \"1m\")\n",
    "conf.set(\"spark.shuffle.unsafe.file.output.buffer\", \"1m\")\n",
    "conf.set(\"spark.sql.shuffle.partitions\", \"18\")  # 3 * cores available (6)\n",
    "conf.set(\"spark.sql.adaptive.enabled\", \"true\") # enable Adaptive Query Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.config(conf=conf).getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('spark.sql.shuffle.partitions', '18'),\n",
       " ('spark.default.parallelism', '6'),\n",
       " ('spark.driver.host', 'e75c6ee053ae'),\n",
       " ('spark.sql.adaptive.enabled', 'true'),\n",
       " ('spark.executor.id', 'driver'),\n",
       " ('spark.app.name', 'ms_malware_pred'),\n",
       " ('spark.executor.cores', '2'),\n",
       " ('spark.shuffle.unsafe.file.output.buffer', '1m'),\n",
       " ('spark.app.id', 'app-20200904102236-0020'),\n",
       " ('spark.executor.memory', '16g'),\n",
       " ('spark.driver.port', '37109'),\n",
       " ('spark.driver.memory', '3g'),\n",
       " ('spark.shuffle.file.buffer', '1m'),\n",
       " ('spark.rdd.compress', 'True'),\n",
       " ('spark.master', 'spark://spark-master:7077'),\n",
       " ('spark.serializer.objectStreamReset', '100'),\n",
       " ('spark.driver.maxResultSize', '0'),\n",
       " ('spark.submit.pyFiles', ''),\n",
       " ('spark.submit.deployMode', 'client'),\n",
       " ('spark.ui.showConsoleProgress', 'true')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sparkContext.getConf().getAll()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = (spark.read.format('csv')\n",
    "      .option('inferSchema', 'true')\n",
    "      .option('header', 'true')\n",
    "      .option('quote', '\\\"')\n",
    "      .option('escape', '\\\"')\n",
    "      .load('hdfs://namenode:9000/data/train.csv') # train|test.csv\n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[MachineIdentifier: string, ProductName: string, EngineVersion: string, AppVersion: string, AvSigVersion: string, IsBeta: int, RtpStateBitfield: int, IsSxsPassiveMode: int, DefaultBrowsersIdentifier: int, AVProductStatesIdentifier: int, AVProductsInstalled: int, AVProductsEnabled: int, HasTpm: int, CountryIdentifier: int, CityIdentifier: int, OrganizationIdentifier: int, GeoNameIdentifier: int, LocaleEnglishNameIdentifier: int, Platform: string, Processor: string, OsVer: string, OsBuild: int, OsSuite: int, OsPlatformSubRelease: string, OsBuildLab: string, SkuEdition: string, IsProtected: int, AutoSampleOptIn: int, PuaMode: string, SMode: int, IeVerIdentifier: int, SmartScreen: string, Firewall: int, UacLuaenable: int, Census_MDC2FormFactor: string, Census_DeviceFamily: string, Census_OEMNameIdentifier: int, Census_OEMModelIdentifier: int, Census_ProcessorCoreCount: int, Census_ProcessorManufacturerIdentifier: int, Census_ProcessorModelIdentifier: int, Census_ProcessorClass: string, Census_PrimaryDiskTotalCapacity: double, Census_PrimaryDiskTypeName: string, Census_SystemVolumeTotalCapacity: int, Census_HasOpticalDiskDrive: int, Census_TotalPhysicalRAM: int, Census_ChassisTypeName: string, Census_InternalPrimaryDiagonalDisplaySizeInInches: double, Census_InternalPrimaryDisplayResolutionHorizontal: int, Census_InternalPrimaryDisplayResolutionVertical: int, Census_PowerPlatformRoleName: string, Census_InternalBatteryType: string, Census_InternalBatteryNumberOfCharges: double, Census_OSVersion: string, Census_OSArchitecture: string, Census_OSBranch: string, Census_OSBuildNumber: int, Census_OSBuildRevision: int, Census_OSEdition: string, Census_OSSkuName: string, Census_OSInstallTypeName: string, Census_OSInstallLanguageIdentifier: int, Census_OSUILocaleIdentifier: int, Census_OSWUAutoUpdateOptionsName: string, Census_IsPortableOperatingSystem: int, Census_GenuineStateName: string, Census_ActivationChannel: string, Census_IsFlightingInternal: int, Census_IsFlightsDisabled: int, Census_FlightRing: string, Census_ThresholdOptIn: int, Census_FirmwareManufacturerIdentifier: int, Census_FirmwareVersionIdentifier: int, Census_IsSecureBootEnabled: int, Census_IsWIMBootEnabled: int, Census_IsVirtualDevice: int, Census_IsTouchEnabled: int, Census_IsPenCapable: int, Census_IsAlwaysOnAlwaysConnectedCapable: int, Wdft_IsGamer: int, Wdft_RegionIdentifier: int, HasDetections: int]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# persists the df to mem and disk to speed up down-stream operations\n",
    "df.persist(StorageLevel.MEMORY_AND_DISK)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8921483"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count() # execute the lazy DAG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save as parquet file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "(df\n",
    " .coalesce(1) \n",
    " .write.format('parquet')\n",
    " .mode('overwrite')\n",
    " .save('hdfs://namenode:9000/data/train.parquet')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper functions\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# added 'MachineIdentifier' in numeric list to enable common join \n",
    "numeric_cols = []\n",
    "def get_num_cols(_df):\n",
    "    global numeric_cols\n",
    "    numeric_cols = [x[0] for x in _df.dtypes if x[1] in ['int', 'double']]\n",
    "    return numeric_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "string_cols = []\n",
    "def get_string_cols(_df):\n",
    "    global string_cols\n",
    "    string_cols = [x[0] for x in _df.dtypes if x[1] == 'string']\n",
    "    return string_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_null_count(_df, _col):\n",
    "    # return count of null values in _col\n",
    "    df1 = _df.select(F.count(F.when(F.isnull(_col), _col)).alias('null_count'))\n",
    "    df2 = _df.groupby(_col).count().sort(F.desc('count'))\n",
    "    df1.show()\n",
    "    df2.show(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pivot_plot(_df, col, count=20):\n",
    "    col_distinct_count = _df.select(col).distinct().count()\n",
    "    pdf = (_df.groupby(col, 'HasDetections')\n",
    "           .agg(F.count(col).alias(col+'Count'), F.count('HasDetections').alias('HasDetectionsCount'))\n",
    "           .sort(F.desc(col+'Count'))\n",
    "           .limit(count)\n",
    "           .selectExpr(\n",
    "               col,'HasDetections','HasDetectionsCount'\n",
    "           )).toPandas()\n",
    "    print(f\"Distinct values count: {col_distinct_count}\")\n",
    "    return pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_type(col):\n",
    "    d = dict(df.dtypes)\n",
    "    return d.get(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Plot:\n",
    "    \"\"\" \n",
    "    takes a col keyword for the column to plot, gets a pandas data frame and plots a sns catplot\n",
    "    of the top 40 col factors and their 'HasDetections' count\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, *args, **kwargs):\n",
    "        self.kwargs = {k:v for k,v in kwargs.items()}\n",
    "        self.col = kwargs.get('col')\n",
    "        self._df = kwargs.get('df')\n",
    "        self._plot(self._get_seaborn_pdf())\n",
    "        \n",
    "    def _get_seaborn_pdf(self):\n",
    "        pdf = (self._df.groupby(self.col, 'HasDetections')\n",
    "               .agg(F.count(self.col).alias(self.col+'Count'), F.count('HasDetections').alias('HasDetectionsCount'))\n",
    "               .sort(F.desc(self.col+'Count'))\n",
    "               .limit(40)\n",
    "               .selectExpr(\n",
    "                   self.col,self.col+'Count','HasDetections','HasDetectionsCount'\n",
    "               )).toPandas()\n",
    "        return pdf\n",
    "    \n",
    "    def _plot(self, pdf):\n",
    "        g = sns.catplot(x=self.col, y='HasDetectionsCount', data=pdf, kind='bar', hue='HasDetections')\n",
    "        g.set_xticklabels(rotation=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def truncate(col):\n",
    "    print(f\"Original count of unique values: {df.select(col).distinct().count()}\")\n",
    "    fe_col_name = col + '_fe'\n",
    "    _df = (df_fe.withColumn(fe_col_name, F.regexp_extract(col,r'\\d.\\d+.(\\d+).\\d+',1))  # change regex capture group to truncate field\n",
    "        .groupby(fe_col_name, 'HasDetections').count().sort(F.desc('count'))\n",
    "    )\n",
    "    Plot(col=col)\n",
    "    print(f\"Count of unique values: {_df.select(fe_col_name).distinct().count()}\")\n",
    "    pdf = _df.toPandas().loc[:40,]\n",
    "#     print(pdf.loc[:,fe_col_name].values)\n",
    "    f, ax = plt.subplots(figsize=(11, 9))\n",
    "#     g = (sns.catplot(x=fe_col_name, y='count', data=pdf, kind='bar', order=pdf.loc[:,fe_col_name].values)\n",
    "#          .set_xticklabels(labels=pdf.loc[:,fe_col_name].values,rotation=90)\n",
    "#         )\n",
    "    g = (sns.barplot(x=fe_col_name, y='count', hue='HasDetections', data=pdf, order=pdf.loc[:,fe_col_name].values)\n",
    "     .set_xticklabels(labels=pdf.loc[:,fe_col_name].values, rotation=90)\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning/EDA\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop columns with high occurence of null values > 70%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_df = df.select(\n",
    "    # get count of null values for each column\n",
    "#     [(F.count(F.when(F.isnull(c), c))).alias(c) for c in df.columns]\n",
    "    [(F.count(F.when(F.isnull(c), c))).alias(c) for c in df.columns]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create pandas dataframe: values are null counts of each column\n",
    "pdf = pd.DataFrame([_df.select(col).first() for col in _df.columns], _df.columns, columns=['count_null_values'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf = pdf.sort_values('count_null_values', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_rows = df.count()\n",
    "pdf['null_ratio'] = pdf.count_null_values/num_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop_cols = ['PuaMode','Census_ProcessorClass','DefaultBrowsersIdentifier','Census_IsFlightingInternal','Census_InternalBatteryType']\n",
    "drop_cols = list(pdf[(pdf['null_ratio'] > .70)].index.values)\n",
    "drop_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(*drop_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Impute remaining missing values to -1 for numeric and '-1' for string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_num_cols(df)\n",
    "get_string_cols(df)\n",
    "df = df.fillna(-1, numeric_cols)\n",
    "df = df.fillna('-1', string_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split cols into numeric and string groups\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_num_cols(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_string_cols(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get skewness of columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df_skew = df.select(\n",
    "   [F.skewness(_col).alias(_col) for _col in df.columns]\n",
    ")\n",
    "pdf_skew = pd.DataFrame([df_skew.select(_col).first() for _col in df_skew.columns], df_skew.columns, columns=['skewness'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_skew.sort_values('skewness', ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize skewed features before dropping\n",
    "* can't use for test.csv because `HasDetections` column is not present"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot_plot(df, 'Census_PrimaryDiskTotalCapacity')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = Plot(df=df, col='Census_PrimaryDiskTotalCapacity')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Maybe this could be a discriminating feature? But it's cardinality is very high--perhaps use hashing trick/binning to reduce dimensionality\n",
    "* Hashing/binning reduces model interpretability, perhaps use quartile transformation to maintain some sense of original unit?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = Plot(df=df, col='UacLuaenable')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = Plot(df=df,col='SmartScreen')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* After reviewing the plot of this feature *SmartScreen*, decided not to drop it due to the potential discriminating effect at predicting P(Y|x)\n",
    "* TODO: write function to standardize values (e.g. off -> Off)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot_plot(df, 'SmartScreen')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Plot(df=df,col='IsBeta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Plot(df=df,col='AutoSampleOptIn')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop skewed columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# skew_drop_cols = ['IsBeta', 'AutoSampleOptIn', 'UacLuaenable']\n",
    "skew_drop_cols = pdf_skew[pdf_skew['skewness'] > 100]\n",
    "skew_drop_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skew_drop_cols = [col for col in list(skew_drop_cols.index.values) if col not in ['SmartScreen', 'Census_PrimaryDiskTotalCapacity']]\n",
    "skew_drop_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(*skew_drop_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_num_cols(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_string_cols(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze distribution of columns by HasDetections column\n",
    "* can't use for test.csv because `HasDetections` column is not present"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Plot(df=df,col='CountryIdentifier')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Plot(df=df,col='Census_OSVersion')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Plot(df=df,col='RtpStateBitfield')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* not sure why this feature didn't show as skewed in earlier analysis -- clearly it is skewed and doesn't appear to provide much predication power"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot_plot(df,'RtpStateBitfield')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = Plot(df=df,col='EngineVersion')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = Plot(df=df,col='AppVersion')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = Plot(df=df,col='AvSigVersion')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get relative frequency of largest factor for each categorical feature\n",
    "* drop columns where one factor is greater than 90% of column density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "def analyze_rel_freq():\n",
    "    cols = df.columns\n",
    "    rel_freqs = []\n",
    "    for col in cols:\n",
    "        rel_freqs.append((col, (df.groupby(col)\n",
    "         .count()\n",
    "         .withColumn('rel_freq', F.col('count')/df.count())\n",
    "         .orderBy(F.desc('count')).orderBy(F.desc('rel_freq'))\n",
    "        ).rdd.take(1)[0].rel_freq))\n",
    "    return rel_freqs\n",
    "rel_freqs = analyze_rel_freq()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rel_freqs = [('MachineIdentifier', 1.1208898789584646e-07), ('ProductName', 0.9893556934424468), ('EngineVersion', 0.43098966842171865), ('AppVersion', 0.5760504167300436), ('AvSigVersion', 0.011468608974539322), ('RtpStateBitfield', 0.969736421624073), ('IsSxsPassiveMode', 0.9826662226448226), ('AVProductStatesIdentifier', 0.652869595783571), ('AVProductsInstalled', 0.6959485323236059), ('AVProductsEnabled', 0.9700294222384328), ('HasTpm', 0.9879710581749693), ('CountryIdentifier', 0.04451860750056913), ('CityIdentifier', 0.0364747654621995), ('OrganizationIdentifier', 0.47037661787844015), ('GeoNameIdentifier', 0.17171237113829618), ('LocaleEnglishNameIdentifier', 0.23477991271182155), ('Platform', 0.9660630413127503), ('Processor', 0.9085300056055703), ('OsVer', 0.9676132320153499), ('OsBuild', 0.43888678597493264), ('OsSuite', 0.6232888635219055), ('OsPlatformSubRelease', 0.43888734641987215), ('OsBuildLab', 0.4100438234315976), ('SkuEdition', 0.6180969016025699), ('IsProtected', 0.9418032853954886), ('SMode', 0.9392881205960937), ('IeVerIdentifier', 0.4355600969031718), ('SmartScreen', 0.48379658404325826), ('Firewall', 0.9685625136538398), ('Census_MDC2FormFactor', 0.6415210341150681), ('Census_DeviceFamily', 0.998382555904663), ('Census_OEMNameIdentifier', 0.14428935189362577), ('Census_OEMModelIdentifier', 0.034162705908871875), ('Census_ProcessorCoreCount', 0.6086648374491102), ('Census_ProcessorManufacturerIdentifier', 0.8787012204136914), ('Census_ProcessorModelIdentifier', 0.03242543868547415), ('Census_PrimaryDiskTotalCapacity', 0.3185042217756846), ('Census_PrimaryDiskTypeName', 0.6508787832695528), ('Census_SystemVolumeTotalCapacity', 0.005940940536455655), ('Census_HasOpticalDiskDrive', 0.9228127207102227), ('Census_TotalPhysicalRAM', 0.4589497060073981), ('Census_ChassisTypeName', 0.5883340247355737), ('Census_InternalPrimaryDiagonalDisplaySizeInInches', 0.34158345647242727), ('Census_InternalPrimaryDisplayResolutionHorizontal', 0.5060889540449721), ('Census_InternalPrimaryDisplayResolutionVertical', 0.5574881440675278), ('Census_PowerPlatformRoleName', 0.6930358999731323), ('Census_InternalBatteryNumberOfCharges', 0.5664309397888221), ('Census_OSVersion', 0.15845201969224174), ('Census_OSArchitecture', 0.9085804456501234), ('Census_OSBranch', 0.449382462534536), ('Census_OSBuildNumber', 0.44935141388488886), ('Census_OSBuildRevision', 0.15845269222616912), ('Census_OSEdition', 0.3889477791976962), ('Census_OSSkuName', 0.38893410434117287), ('Census_OSInstallTypeName', 0.29233222772491974), ('Census_OSInstallLanguageIdentifier', 0.3563602598357246), ('Census_OSUILocaleIdentifier', 0.3554144529558595), ('Census_OSWUAutoUpdateOptionsName', 0.4432555663671612), ('Census_IsPortableOperatingSystem', 0.9994547991628746), ('Census_GenuineStateName', 0.8829918747813564), ('Census_ActivationChannel', 0.5299106661975369), ('Census_IsFlightsDisabled', 0.9819972755650602), ('Census_FlightRing', 0.9365796022925785), ('Census_ThresholdOptIn', 0.635244723326828), ('Census_FirmwareManufacturerIdentifier', 0.3025369212719455), ('Census_FirmwareVersionIdentifier', 0.017949145898725583), ('Census_IsSecureBootEnabled', 0.5139771044791545), ('Census_IsWIMBootEnabled', 0.6343903810610859), ('Census_IsVirtualDevice', 0.991184985724907), ('Census_IsTouchEnabled', 0.8744568587980271), ('Census_IsPenCapable', 0.9619290873501637), ('Census_IsAlwaysOnAlwaysConnectedCapable', 0.9350431985354901), ('Wdft_IsGamer', 0.6920534399942252), ('Wdft_RegionIdentifier', 0.2017719475562527), ('HasDetections', 0.5002073085831134)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_rel_freq_gt_90 = [x[0] for x in sorted(rel_freqs, key=lambda x: x[1], reverse=True) if x[1] > .9]\n",
    "drop_rel_freq_gt_90"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(*drop_rel_freq_gt_90)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering\n",
    "* [x] TODO: Discretize Census_SystemVolumeTotalCapacity [299451]\n",
    "* [-] TODO: Discretize Census_OEMModelIdentifier\n",
    "* [x] TODO: Standardize *SmartScreen* values\n",
    "* [x] TODO: Discretize (hashing trick/binning) of *Census_PrimaryDiskTotalCapacity*; decided to discretize based on quartile values\n",
    "* [x] TODO: Truncate EngineVersion [1.1.15100.1]\n",
    "* [x] TODO: Truncate AppVersion [4.18.1807.18075]\n",
    "* [x] TODO: Truncate AvSigVersion [1.273.1735.0]\n",
    "* [x] TODO: Discretize Census_InternalBatteryNumberOfCharges [4294967295.0]\n",
    "* [x] TODO: Discretize Census_TotalPhysicalRAM [4096]\n",
    "* [ ] TODO: Discretize Census_InternalPrimaryDisplayResolutionHorizontal [1440]\n",
    "* [ ] TODO: Discretize Census_InternalPrimaryDisplayResolutionVertical [900]\n",
    "* [x] TODO: Onehot encode categorical data\n",
    "* [ ] TODO: Create hashing transformer function\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Cardinality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from pyspark.sql.functions import approx_count_distinct\n",
    "# col_distinct_counts = [(_col, df_fe.select(_col).distinct().count()) for _col in numeric_cols + string_cols]\n",
    "col_distinct_counts = sorted([(_col, df.select(approx_count_distinct(_col, .1)).rdd.take(1)[0][0]) for _col in df.columns], key=lambda x: x[1], reverse=True)\n",
    "col_distinct_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fe = df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discretize `Census_SystemVolumeTotalCapacity`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fe.select('Census_SystemVolumeTotalCapacity').summary().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@F.udf(returnType=T.StringType())\n",
    "def discretize_Census_SystemVolumeTotalCapacity(num):\n",
    "    # (475965.0, INF]\n",
    "    if num > 475798.0:\n",
    "        return 'large'\n",
    "    # (239500.0, 475965.0]\n",
    "    elif (num > 239500.0 and num <= 475965.0): \n",
    "        return 'med'\n",
    "    # (113922.0, 239500.0]\n",
    "    elif (num > 113922.0 and num <= 239500.0):\n",
    "        return 'small'\n",
    "    else:\n",
    "        return 'unknown'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fe = (df_fe.select('*')\n",
    "           .withColumn('Census_SystemVolumeTotalCapacity', discretize_Census_SystemVolumeTotalCapacity(df.Census_SystemVolumeTotalCapacity))\n",
    "     )\n",
    "df_fe.groupby('Census_SystemVolumeTotalCapacity').count().sort(F.desc('count')).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discretize `Census_OEMModelIdentifier`\n",
    "* don't currently see a way to discretize this feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot_plot(df_fe, 'Census_OEMModelIdentifier')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Plot(df=df,col='Census_OEMModelIdentifier')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standardize `SmartScreen` values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fe = (df_fe.select('*')\n",
    "      .withColumn('SmartScreen', F.regexp_replace('SmartScreen', r'off', 'Off'))\n",
    "      .withColumn('SmartScreen', F.regexp_replace('SmartScreen', r'OFF', 'Off'))\n",
    "      .withColumn('SmartScreen', F.regexp_replace('SmartScreen', r'on', 'On'))\n",
    "      .withColumn('SmartScreen', F.regexp_replace('SmartScreen', r'&#x02;', '2'))\n",
    "      .withColumn('SmartScreen', F.regexp_replace('SmartScreen', r'&#x01;', '1'))\n",
    "      .withColumn('SmartScreen', F.regexp_replace('SmartScreen', r'&#x03;', '3'))\n",
    "      .withColumn('SmartScreen', F.regexp_replace('SmartScreen', r'requireadmin', 'RequireAdmin'))\n",
    "      .withColumn('SmartScreen', F.regexp_replace('SmartScreen', r'Promt', 'Prompt'))\n",
    "     )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discretize `Census_PrimaryDiskTotalCapacity`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot_plot(df_fe,'Census_PrimaryDiskTotalCapacity')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fe.select('Census_PrimaryDiskTotalCapacity').summary().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@F.udf(returnType=T.StringType())\n",
    "def discretize_col(num):\n",
    "    # (953869.0, INF]\n",
    "    if num > 953869.0:\n",
    "        return 'large'\n",
    "    # (476940.0, 953869.0]\n",
    "    elif (num > 476940.0 and num <= 953869.0): \n",
    "        return 'med'\n",
    "    # (238475.0, 476940.0]\n",
    "    elif (num > 238475.0 and num <= 476940.0):\n",
    "        return 'small'\n",
    "    else:\n",
    "        return 'unknown'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fe = (df_fe.select('*')\n",
    "           .withColumn('Census_PrimaryDiskTotalCapacity', discretize_col(df.Census_PrimaryDiskTotalCapacity))\n",
    "     )\n",
    "df_fe.groupby('Census_PrimaryDiskTotalCapacity').count().sort(F.desc('count')).show()\n",
    "\n",
    "# verify count \n",
    "# print('small', df.filter((df.Census_PrimaryDiskTotalCapacity > 238475.0) & (df.Census_PrimaryDiskTotalCapacity <= 476940.0)).count())\n",
    "# print('med', df.filter((df.Census_PrimaryDiskTotalCapacity > 476940.0) & (df.Census_PrimaryDiskTotalCapacity <= 953869.0)).count())\n",
    "# print('x-large', df.filter((df.Census_PrimaryDiskTotalCapacity > 953869.0)).count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Plot(df=df_fe,col='Census_SystemVolumeTotalCapacity')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_num_cols(df)\n",
    "get_string_cols(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discretize `EngineVersion` `AppVersion` `AvSigVersion`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fe = df_fe.select('*').withColumn('EngineVersion', F.regexp_extract('EngineVersion',r'\\d.\\d+.(\\d+.\\d+)',1))\n",
    "df_fe = df_fe.select('*').withColumn('AppVersion', F.regexp_extract('AppVersion',r'\\d.\\d+.(\\d+.\\d+)',1))\n",
    "df_fe = df_fe.select('*').withColumn('AvSigVersion', F.regexp_extract('AvSigVersion',r'\\d.\\d+.(\\d+).\\d+',1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discretize `Census_InternalBatteryNumberOfCharges`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fe = (df_fe.select('*')\n",
    "         .withColumn('Census_InternalBatteryNumberOfCharges', (F.col('Census_InternalBatteryNumberOfCharges').cast('int')))\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fe.select('Census_InternalBatteryNumberOfCharges').summary().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot_plot(df_fe, 'Census_InternalBatteryNumberOfCharges')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Plot(df=df_fe,col='Census_InternalBatteryNumberOfCharges')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fe = df_fe.drop('Census_InternalBatteryNumberOfCharges')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discretize `Census_TotalPhysicalRAM`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Plot(df=df_fe,col='Census_TotalPhysicalRAM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot_plot(df_fe, 'Census_TotalPhysicalRAM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fe.select('Census_TotalPhysicalRAM').summary().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize ram by 1024 to reduce cardinality\n",
    "df_fe = (df_fe.select('*')\n",
    "         .withColumn('Census_TotalPhysicalRAM', F.col('Census_TotalPhysicalRAM')/1024)\n",
    "         .withColumn('Census_TotalPhysicalRAM', F.round(F.col('Census_TotalPhysicalRAM'),1))\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Plot(df=df_fe, col='Census_TotalPhysicalRAM')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use Hashing Trick to deal with columns with high cardinality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "fe_distinct_count = sorted([(_col, df_fe.select(approx_count_distinct(_col, .1)).rdd.take(1)[0][0]) for _col in df_fe.columns], key=lambda x: x[1], reverse=True)\n",
    "fe_distinct_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[x for x in fe_distinct_count if x[1] > 1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [x[0] for x in fe_distinct_count if x[1] > 1000 if x[0] != 'MachineIdentifier'] \n",
    "cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import FeatureHasher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hasher = FeatureHasher(inputCols=cols,outputCol='hash_features')\n",
    "featurized = hasher.transform(df_fe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "featurized.select('hash_features').show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform ChiSquareTest to determine feature independence\n",
    "- (SPSS article) However, this does not mean the variables are strongly associated; a weak association in a large sample size may also result in p = 0.000\n",
    "- (machinelearningmastery.com) The variables are considered independent if the observed and expected frequencies are similar, that the levels of the variables do not interact, are not dependent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "featurized.select(featurized.columns[25]).distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "featurized.select(featurized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "va_df.select()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.ml.stat import ChiSquareTest\n",
    "\n",
    "r = ChiSquareTest.test(featurized, \"hash_features\", \"HasDetections\").head()\n",
    "print(\"pValues: \" + str(r.pValues))\n",
    "print(\"degreesOfFreedom: \" + str(r.degreesOfFreedom))\n",
    "print(\"statistics: \" + str(r.statistics))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "chi_pdf = pd.DataFrame(r.statistics.toArray(), index=low_dim_cols_int, columns=['chi_stat']).sort_values('chi_stat',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = chi_pdf.index.to_list()\n",
    "f, ax = plt.subplots(figsize=(11, 9))\n",
    "g = (sns.barplot(x=cols, y='chi_stat',data=chi_pdf)\n",
    "     .set_xticklabels(labels=cols, rotation=90)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.stat import Correlation\n",
    "\n",
    "r1 = Correlation.corr(va_df, \"features\").collect()[0][0]\n",
    "# print(\"Pearson correlation matrix:\\n\" + str(r1[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrmatrix = r1.toArray().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_df = spark.createDataFrame(corrmatrix, low_dim_cols_int)\n",
    "corr_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_corr_pdf = corr_df.toPandas()\n",
    "pdf_corr_pdf.index = low_dim_cols_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a mask for the upper triangle\n",
    "mask = np.triu(np.ones_like(pdf_corr_pdf, dtype=np.bool))\n",
    "\n",
    "f, ax = plt.subplots(figsize=(11, 9))\n",
    "\n",
    "# Generate a custom diverging colormap\n",
    "cmap = sns.diverging_palette(220, 10, as_cmap=True)\n",
    "\n",
    "# Draw the heatmap with the mask and correct aspect ratio\n",
    "sns.heatmap(pdf_corr_pdf, mask=mask, cmap=cmap, vmax=.3, center=0,\n",
    "            square=True, linewidths=.5, cbar_kws={\"shrink\": .5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize=(11, 9))\n",
    "sns.heatmap(pdf_corr_pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.stat import ChiSquareTest\n",
    "\n",
    "def is_independent(cols):\n",
    "#     va = VectorAssembler(inputCols='cols', outputCol='features')\n",
    "#     _df = hash.transform(hash_data).select('hash_features', 'HasDetections')\n",
    "    r = ChiSquareTest.test(hash_data, 'hash_features', 'HasDetections').head()\n",
    "    print(\"pValues: \" + str(r.pValues))\n",
    "    print(\"degreesOfFreedom: \" + str(r.degreesOfFreedom))\n",
    "    print(\"statistics: \" + str(r.statistics))\n",
    "is_independent(cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# todo create pipeline function with df parameter\n",
    "def fe(_df, test=False):\n",
    "#     indexers = [feature.StringIndexer(inputCol=col, outputCol=col+\"_index\").fit(_df) for col in _df.columns if col not in ['MachineIdentifier','HasDetections']]\n",
    "    indexers = [feature.StringIndexer(inputCol=col, outputCol=col+\"_index\", handleInvalid='skip').fit(_df) for col in _df.columns if col not in ['MachineIdentifier','HasDetections']]\n",
    "    idx_df = Pipeline(stages=indexers).fit(_df).transform(_df)\n",
    "    \n",
    "    input_cols = [col for col in idx_df.columns if 'index' in col]\n",
    "    output_cols = [col + \"_vec\" for col in input_cols]\n",
    "    one_hot = feature.OneHotEncoder(inputCols=input_cols, outputCols=output_cols).fit(idx_df).transform(idx_df)\n",
    "    \n",
    "    if test:\n",
    "        va = feature.VectorAssembler(inputCols=[col for col in one_hot.columns if 'vec' in col], outputCol='features').transform(one_hot).select('MachineIdentifier','features')\n",
    "    else:\n",
    "        va = feature.VectorAssembler(inputCols=[col for col in one_hot.columns if 'vec' in col], outputCol='features').transform(one_hot).select('MachineIdentifier','features', 'HasDetections')\n",
    "    \n",
    "    return va"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "va_train = fe(df_train, test=False)\n",
    "# va_test = fe(df_test, test=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# index all features to numerical index\n",
    "indexers = [feature.StringIndexer(inputCol=col, outputCol=col+\"_index\").fit(df_train) for col in df_train.columns if col not in ['MachineIdentifier','HasDetections']]\n",
    "idx_df = Pipeline(stages=indexers).fit(df_train).transform(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one hot encode features to vector\n",
    "input_cols = [col for col in idx_df.columns if 'index' in col]\n",
    "output_cols = [col + \"_vec\" for col in input_cols]\n",
    "one_hot = feature.OneHotEncoder(inputCols=input_cols, outputCols=output_cols).fit(idx_df).transform(idx_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assemble vectors into feature column\n",
    "va = feature.VectorAssembler(inputCols=[col for col in one_hot.columns if 'vec' in col], outputCol='features').transform(one_hot).select('MachineIdentifier','features','HasDetections')\n",
    "\n",
    "# test dataset\n",
    "# va = feature.VectorAssembler(inputCols=[col for col in one_hot.columns if 'vec' in col], outputCol='features').transform(one_hot).select('MachineIdentifier','features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "va_train.persist(StorageLevel.MEMORY_AND_DISK)\n",
    "# va_test.persist(StorageLevel.MEMORY_AND_DISK)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "va_train.count()\n",
    "# va_test.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read-in Cleaned data\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = spark.read.parquet('hdfs://namenode:9000/data/df_fe.parquet').orderBy(F.asc('MachineIdentifier')).repartition(18, 'MachineIdentifier')\n",
    "df_train = spark.read.parquet('hdfs://namenode:9000/data/df_fe.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# not going to manually repartition to test AQE\n",
    "df_test = spark.read.parquet('hdfs://namenode:9000/data/df_test.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_drop_cols = [x for x in (set(df_train.columns) - set(df_test.columns)) if x != 'HasDetections']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_drop_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.drop(*model_drop_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(df_train.columns) - set(df_test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.persist(StorageLevel.MEMORY_AND_DISK)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.persist(StorageLevel.MEMORY_AND_DISK)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.count() # execute the lazy DAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.count() # execute lazy DAG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_df, validation_df, testing_df = va_train.randomSplit([0.6, 0.3, 0.1], seed=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logestic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "lr = LogisticRegression(featuresCol='features', labelCol='HasDetections')\n",
    "pipeline = Pipeline(stages=[\n",
    "#     feature.StringIndexer(inputCol='features',outputCol='str_idx', handleInvalid=\"keep\"),\n",
    "#     feature.OneHotEncoderEstimator(inputCols=['str_idx'], outputCols=['feature']),\n",
    "    lr\n",
    "    \n",
    "]).fit(training_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.transform(validation_df).\\\n",
    "    select(F.expr('float(prediction = HasDetections)').alias('correct')).\\\n",
    "    select(F.avg('correct')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.transform(testing_df).\\\n",
    "    select(F.expr('float(prediction = HasDetections)').alias('correct')).\\\n",
    "    select(F.avg('correct')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_results = pipeline.transform(va_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "va_test.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_results.show(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LR Model Tuning\n",
    "\n",
    "* [ ] need to reduce cardinality of features before grid-searching\n",
    "* Perform grid-search over regularization parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paramGrid = (ParamGridBuilder() \n",
    "                 .addGrid(pipeline.stages[0].regParam, [0.0, 0.01, 0.02]) \n",
    "                 .addGrid(pipeline.stages[0].elasticNetParam, [0.0, 0.2, 0.4]) \n",
    "                 .build()\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Loop over each parameter mapping in paramGrid and fit model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_models = []\n",
    "for g in range(len(paramGrid)):\n",
    "    print(\"Fitting model {}\".format(g))\n",
    "    _model = en_lr_pipeline.fit(validation_df, paramGrid[g])\n",
    "    lr_models.append(_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest\n",
    "* [ ] OOM errors; believe these are occuring because of high cardinality of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "rf = RandomForestClassifier(featuresCol='features', labelCol='HasDetections', maxDepth=3, numTrees=10, \n",
    "                            featureSubsetStrategy='sqrt', impurity='gini', seed=0, maxBins=32)\n",
    "pipeline = Pipeline(stages=[\n",
    "#     feature.StringIndexer(inputCol='features',outputCol='str_idx', handleInvalid=\"keep\"),\n",
    "#     feature.OneHotEncoderEstimator(inputCols=['str_idx'], outputCols=['feature']),\n",
    "    rf\n",
    "    \n",
    "]).fit(training_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.transform(validation_df).\\\n",
    "    select(F.avg(F.expr('float(HasDetections = prediction)')).alias('accuracy')).\\\n",
    "    first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.groupby('HasDetections').count().show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
